{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# os.environ[\"RUNFILES_DIR\"] = \"/Library/Frameworks/Python.framework/Versions/3.8/share/plaidml\"\n",
    "# os.environ[\"PLAIDML_NATIVE_PATH\"] = \"/Library/Frameworks/Python.framework/Versions/3.8/lib/libplaidml.dylib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "default_image_size = tuple((256, 256))\n",
    "image_size = 0\n",
    "directory_root = './train'\n",
    "width=256\n",
    "height=256\n",
    "depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = cv2.resize(image, default_image_size)   \n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Tomato___Bacterial_spot ...\n",
      "[INFO] Processing Tomato___Early_blight ...\n",
      "[INFO] Processing Tomato___healthy ...\n",
      "[INFO] Processing Tomato___Late_blight ...\n",
      "[INFO] Processing Tomato___Leaf_Mold ...\n",
      "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
      "[INFO] Processing Tomato___Spider_mites Two-spotted_spider_mite ...\n",
      "[INFO] Processing Tomato___Target_Spot ...\n",
      "[INFO] Processing Tomato___Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "image_list, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    for directory in root_dir :\n",
    "        # remove .DS_Store from list\n",
    "        if directory == \".DS_Store\" :\n",
    "            root_dir.remove(directory)\n",
    "        \n",
    "\n",
    "    for plant_disease_folder in root_dir:\n",
    "        print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "        plant_disease_image_list = listdir(f\"{directory_root}/{plant_disease_folder}/\")\n",
    "\n",
    "        for single_plant_disease_image in plant_disease_image_list :\n",
    "            if single_plant_disease_image == \".DS_Store\" :\n",
    "                plant_disease_image_list.remove(single_plant_disease_image)\n",
    "\n",
    "        for image in plant_disease_image_list[:1500]:\n",
    "            image_directory = f\"{directory_root}/{plant_disease_folder}/{image}\"\n",
    "            if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
    "                image_list.append(convert_image_to_array(image_directory))\n",
    "                label_list.append(plant_disease_folder)\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Spliting data to train, test\n"
     ]
    }
   ],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "np_image_list = np.array(image_list) / 255.0\n",
    "print(\"[INFO] Spliting data to train, test\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "chanDim = -1\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (depth, height, width)\n",
    "    chanDim = 1\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "# fully-connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "# softmax classifier\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "  2/375 [..............................] - ETA: 33s - loss: 1.2766 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0249s vs `on_train_batch_end` time: 0.1487s). Check your callbacks.\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.6112\n",
      "Epoch 00001: val_loss improved from inf to 1.19297, saving model to model_best_weights.h5\n",
      "375/375 [==============================] - 74s 198ms/step - loss: 0.2849 - accuracy: 0.6112 - val_loss: 1.1930 - val_accuracy: 0.1440\n",
      "Epoch 2/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.7978\n",
      "Epoch 00002: val_loss improved from 1.19297 to 0.09999, saving model to model_best_weights.h5\n",
      "375/375 [==============================] - 70s 188ms/step - loss: 0.1236 - accuracy: 0.7978 - val_loss: 0.1000 - val_accuracy: 0.8267\n",
      "Epoch 3/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.8432\n",
      "Epoch 00003: val_loss did not improve from 0.09999\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0991 - accuracy: 0.8432 - val_loss: 0.6785 - val_accuracy: 0.4220\n",
      "Epoch 4/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.8827\n",
      "Epoch 00004: val_loss did not improve from 0.09999\n",
      "375/375 [==============================] - 68s 182ms/step - loss: 0.0750 - accuracy: 0.8827 - val_loss: 0.1533 - val_accuracy: 0.7580\n",
      "Epoch 5/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.8800\n",
      "Epoch 00005: val_loss did not improve from 0.09999\n",
      "375/375 [==============================] - 68s 182ms/step - loss: 0.0768 - accuracy: 0.8800 - val_loss: 0.3953 - val_accuracy: 0.5957\n",
      "Epoch 6/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9186\n",
      "Epoch 00006: val_loss improved from 0.09999 to 0.09234, saving model to model_best_weights.h5\n",
      "375/375 [==============================] - 69s 185ms/step - loss: 0.0569 - accuracy: 0.9186 - val_loss: 0.0923 - val_accuracy: 0.8307\n",
      "Epoch 7/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9151\n",
      "Epoch 00007: val_loss improved from 0.09234 to 0.04744, saving model to model_best_weights.h5\n",
      "375/375 [==============================] - 69s 185ms/step - loss: 0.0578 - accuracy: 0.9151 - val_loss: 0.0474 - val_accuracy: 0.9250\n",
      "Epoch 8/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9027\n",
      "Epoch 00008: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0637 - accuracy: 0.9027 - val_loss: 0.4535 - val_accuracy: 0.4867\n",
      "Epoch 9/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9145\n",
      "Epoch 00009: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0591 - accuracy: 0.9145 - val_loss: 0.1124 - val_accuracy: 0.8323\n",
      "Epoch 10/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9360\n",
      "Epoch 00010: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0464 - accuracy: 0.9360 - val_loss: 0.0732 - val_accuracy: 0.8797\n",
      "Epoch 11/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9492\n",
      "Epoch 00011: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0382 - accuracy: 0.9492 - val_loss: 0.0591 - val_accuracy: 0.8967\n",
      "Epoch 12/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9591\n",
      "Epoch 00012: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 182ms/step - loss: 0.0322 - accuracy: 0.9591 - val_loss: 0.0520 - val_accuracy: 0.9253\n",
      "Epoch 13/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9528\n",
      "Epoch 00013: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0355 - accuracy: 0.9528 - val_loss: 0.1651 - val_accuracy: 0.8893\n",
      "Epoch 14/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9674\n",
      "Epoch 00014: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0275 - accuracy: 0.9674 - val_loss: 0.1063 - val_accuracy: 0.8390\n",
      "Epoch 15/15\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9514\n",
      "Epoch 00015: val_loss did not improve from 0.04744\n",
      "375/375 [==============================] - 68s 181ms/step - loss: 0.0392 - accuracy: 0.9514 - val_loss: 0.2005 - val_accuracy: 0.7223\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "seed(1)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint('model_best_weights.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "opt= Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# distribution\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt,metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")\n",
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    validation_data=(x_test, y_test),callbacks=[early_stop,checkpoint],\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model1=tf.keras.models.load_model('./model_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection \n",
    "def quantify_image(image, bins=(4, 6, 3)):\n",
    "    # compute a 3D color histogram over the image and normalize it\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins,\n",
    "    [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    # return the histogram\n",
    "    return hist\n",
    "\n",
    "def load_dataset(datasetPath, bins):\n",
    "    # grab the paths to all images in our dataset directory, then\n",
    "    # initialize our lists of images\n",
    "    imagePaths = list(paths.list_images(datasetPath))\n",
    "    data = []\n",
    "    # loop over the image paths\n",
    "    for imagePath in imagePaths:\n",
    "        # load the image and convert it to the HSV color space\n",
    "        image = Image.open(imagePath)\n",
    "        image = np.array(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        # quantify the image and update the data list\n",
    "        features = quantify_image(image, bins)\n",
    "        data.append(features)\n",
    "    # return our data list as a NumPy array\n",
    "    return np.array(data)\n",
    "\n",
    "def anomoly_detect(image):\n",
    "    model_anomoly=pickle.load(open('model.hdf5','rb'))\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    features = quantify_image(hsv, bins=(4, 6, 3))\n",
    "    preds = model_anomoly.predict([features])[0]\n",
    "    return preds\n",
    "\n",
    "\n",
    "data=load_dataset('./data/train_data/',bins=(4,6,3))\n",
    "model = IsolationForest(n_estimators=50, contamination=0.01,random_state=42)\n",
    "model.fit(data)\n",
    "pickle.dump(model, open('model.hdf5', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Tomato___Bacterial_spot ...\n",
      "[INFO] Processing Tomato___Early_blight ...\n",
      "[INFO] Processing Tomato___healthy ...\n",
      "[INFO] Processing Tomato___Late_blight ...\n",
      "[INFO] Processing Tomato___Leaf_Mold ...\n",
      "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
      "[INFO] Processing Tomato___Spider_mites Two-spotted_spider_mite ...\n",
      "[INFO] Processing Tomato___Target_Spot ...\n",
      "[INFO] Processing Tomato___Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "directory_root = './validation'\n",
    "image_list, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    for directory in root_dir :\n",
    "        # remove .DS_Store from list\n",
    "        if directory == \".DS_Store\" :\n",
    "            root_dir.remove(directory)\n",
    "\n",
    "#     for plant_folder in root_dir :\n",
    "#         plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "        \n",
    "\n",
    "    for plant_disease_folder in root_dir:\n",
    "        print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "        plant_disease_image_list = listdir(f\"{directory_root}/{plant_disease_folder}/\")\n",
    "\n",
    "        for single_plant_disease_image in plant_disease_image_list :\n",
    "            if single_plant_disease_image == \".DS_Store\" :\n",
    "                plant_disease_image_list.remove(single_plant_disease_image)\n",
    "\n",
    "        for image in plant_disease_image_list[:500]:\n",
    "            image_directory = f\"{directory_root}/{plant_disease_folder}/{image}\"\n",
    "            if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
    "                image_list.append(convert_image_to_array(image_directory))\n",
    "                label_list.append(plant_disease_folder)\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(image_list)/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=label_binarizer.transform(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Calculating model accuracy\n",
      "144/144 [==============================] - 7s 48ms/step - loss: 0.0549 - accuracy: 0.9280\n",
      "Test Accuracy: 92.80261993408203\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Calculating model accuracy\")\n",
    "scores = model1.evaluate(x_test,y_test)\n",
    "print(f\"Test Accuracy: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/144 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_predict_batch_end` time: 0.0339s). Check your callbacks.\n",
      "144/144 [==============================] - 6s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "x_pre=model1.predict(x_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       425\n",
      "           1       0.92      0.88      0.90       480\n",
      "           2       0.87      0.93      0.90       463\n",
      "           3       0.98      0.94      0.96       470\n",
      "           4       0.90      0.90      0.90       436\n",
      "           5       0.90      0.93      0.91       435\n",
      "           6       0.95      0.82      0.88       457\n",
      "           7       0.94      0.97      0.95       490\n",
      "           8       0.92      0.99      0.95       448\n",
      "           9       0.96      0.99      0.98       481\n",
      "\n",
      "    accuracy                           0.93      4585\n",
      "   macro avg       0.93      0.93      0.93      4585\n",
      "weighted avg       0.93      0.93      0.93      4585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test,axis=-1),np.argmax(x_pre, axis=-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
